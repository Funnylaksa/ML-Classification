{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are test images with their ground_truth class index appeneded:\n",
      "['a_0.jpg' 'b_21.jpg' 'c_7.JPG' 'd_4.jpg' 'e_22.jpg']\n"
     ]
    }
   ],
   "source": [
    "from io_ import readFiles\n",
    "import numpy as np\n",
    "\n",
    "# This is a sample test folder\n",
    "test_folder = 'test_images'\n",
    "image_paths = readFiles(test_folder)\n",
    "print('Below are test images with their ground_truth class index appeneded:')\n",
    "print(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score each of the images based on the likelihood it belongs to a class. Larger scores indicate higher likelihood.\n",
    "\n",
    "Classes are arranged alphabeticall, [1_Capitol, 1_Chijmes,..., 1_scis, americano, ... taco]. Screen-shot is attached.\n",
    "\n",
    "The first thirteen belong to buidings and the next fifty nine belong to food, this makes for a total of 72 classes.\n",
    "\n",
    "Scores should take the form of a [Nx72] array, where N is the number of test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Code for sorting the classes (not needed for project) ##################\n",
    "\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# import numpy as np\n",
    "\n",
    "# train_dir = '../training'\n",
    "\n",
    "\n",
    "\n",
    "# train_datagen = ImageDataGenerator() \n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     train_dir) \n",
    "\n",
    "# a = train_generator.class_indices\n",
    "# l = []\n",
    "# for i in a:\n",
    "#     l.append(i)\n",
    "# np.save('sorted_classes.npy', l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Capitol  is class  0\n",
      "1_library  is class  10\n",
      "cafe_coffee_with_milk  is class  21\n"
     ]
    }
   ],
   "source": [
    "sorted_class = np.load('sorted_classes.npy')\n",
    "print(sorted_class[0], ' is class ', 0)\n",
    "print(sorted_class[10], ' is class ', 10)\n",
    "print(sorted_class[21], ' is class ', 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Your model will be tested as following\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('goog_augment.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "\n",
    "model = tf.keras.models.model_from_json(json_savedModel)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "# Load weights into the new model\n",
    "model.load_weights('goog_augment.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############## Write your test function here ##############\n",
    "\n",
    "\n",
    "# Below is a possible mechanics for score computation;\n",
    "# However, it must be modifed according to pre-processing amd network\n",
    "test_folder = 'test_images'\n",
    "image_paths = readFiles(test_folder)\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "num_images = len(image_paths)\n",
    "scores = np.zeros([num_images, 72])\n",
    "for i,im in enumerate(image_paths):\n",
    "    img = image.load_img(test_folder + '/' + im, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img.reshape([1,224,224,3])\n",
    "    scores[i] = model.predict(img)\n",
    "    \n",
    "\n",
    "#     predictions = model.predict(img)\n",
    "#     score = tf.nn.softmax(predictions[0])\n",
    "    \n",
    "#     print(\n",
    "#     \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "#     .format(sorted_class[np.argmax(score)], 100 * np.max(score))\n",
    "# )\n",
    "    \n",
    "#     percent = predictions[0]\n",
    "#     sorted_a = np.argsort(-percent, axis=-1, kind='quicksort', order=None)\n",
    "    \n",
    "    \n",
    "#     top5 = sorted_a[:5]\n",
    "#     for x in top5:\n",
    "#         print(x, np.round(100 * np.max(score[x]),2), sorted_class[x])\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 72)\n"
     ]
    }
   ],
   "source": [
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the evaluation functions on the first two test images\n",
    "\n",
    "You need not modify code beyond this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy\n",
      "percentage top1 accuracy: 0.5\n",
      "percentage top5 accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from io_ import score\n",
    "print('overall accuracy')\n",
    "\n",
    "# simulated scores\n",
    "scores = np.zeros([2,72])\n",
    "scores[0,0] = 1000\n",
    "scores[1,3] = 1000\n",
    "scores[1,21] = 999\n",
    "\n",
    "# Ground-truth: the first image belongs to class 0; the second image to class 13.\n",
    "gt = np.array([0,21]) \n",
    "\n",
    "top1, top5 = score(scores, gt, 5)\n",
    "print('percentage top1 accuracy:', top1)\n",
    "print('percentage top5 accuracy:', top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on building only\n",
      "percentage top1 accuracy: 1.0\n",
      "percentage top5 accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on building only')\n",
    "mask = gt<13\n",
    "top1, top5 = score(scores[mask,:13], gt[mask], 5)\n",
    "print('percentage top1 accuracy:', top1)\n",
    "print('percentage top5 accuracy:', top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on food only\n",
      "percentage top1 accuracy: 1.0\n",
      "percentage top5 accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on food only')\n",
    "mask = gt>=13\n",
    "top1, top5 = score(scores[mask,13:], gt[mask]-13, 5)\n",
    "print('percentage top1 accuracy:', top1)\n",
    "print('percentage top5 accuracy:', top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
