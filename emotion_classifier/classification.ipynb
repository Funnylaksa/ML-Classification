{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet fuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import csv\n",
    "import numpy as np # linear algebra\n",
    "import collections\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, oversampling, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = 'fuller.csv'\n",
    "image_size=(48, 48)\n",
    "\n",
    "# Helper functions\n",
    "def load_data(data_path):\n",
    "    data_set = pd.read_csv(data_path)\n",
    "    X = data_set[' pixels']\n",
    "    y = data_set['emotion']\n",
    "    return X, y\n",
    "\n",
    "def oversampling(X, y):\n",
    "    X = X.values.reshape(-1, 1)\n",
    "    print('before oversampling:', collections.Counter(y))\n",
    "    \n",
    "    oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "    X_over, y_over = oversample.fit_resample(X.reshape(-1, 1), y)\n",
    "    a = np.array(y_over)\n",
    "    print('after oversampling:', collections.Counter(a))\n",
    "    \n",
    "    y_over = pd.Series(y_over)\n",
    "    y_over= y_over.values.reshape(len(y_over),1)\n",
    "\n",
    "    return X_over, y_over\n",
    "\n",
    "def preprocessing(pixels):\n",
    "    a = []\n",
    "    \n",
    "    for i in range(len(pixels)):\n",
    "            image_string = (pixels)[i].split(' ') \n",
    "            image_data = np.asarray(image_string, dtype=np.uint8).reshape(48,48,1)\n",
    "            a.append(image_data)\n",
    "\n",
    "    return a\n",
    "\n",
    "def reshape(X):\n",
    "    print('before:', X.shape)\n",
    "    a= []\n",
    "    X = pd.Series(X.flatten())\n",
    "    a = preprocessing(X)\n",
    "    X = np.array(a)\n",
    "    print('after:', X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before oversampling: Counter({3: 8989, 4: 6077, 2: 5121, 0: 4953, 5: 4002, 1: 547})\n",
      "after oversampling: Counter({0: 8989, 2: 8989, 4: 8989, 3: 8989, 5: 8989, 1: 8989})\n",
      "before: (43147, 1)\n",
      "after: (43147, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "## Start here ##\n",
    "#Load data\n",
    "X, y = load_data(data_path)\n",
    "\n",
    "#Oversampling so each class has same number of examples\n",
    "X_over, y_over = oversampling(X, y)\n",
    "\n",
    "#train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_over,y_over, test_size=0.2)\n",
    "\n",
    "#Reshape to fit in as input to model\n",
    "X_train = reshape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"4\" #please put your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 19,805,830\n",
      "Trainable params: 19,804,166\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(256, (5, 5),padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2),padding=\"same\"))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43147, 48, 48, 1) (43147, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32360 samples, validate on 10787 samples\n",
      "Epoch 1/20\n",
      "32360/32360 [==============================] - 3483s 108ms/sample - loss: 1.6105 - acc: 0.4163 - val_loss: 1.5152 - val_acc: 0.5206\n",
      "Epoch 2/20\n",
      "32360/32360 [==============================] - 3403s 105ms/sample - loss: 1.4699 - acc: 0.5704 - val_loss: 1.4417 - val_acc: 0.5977\n",
      "Epoch 3/20\n",
      "32360/32360 [==============================] - 3437s 106ms/sample - loss: 1.3951 - acc: 0.6468 - val_loss: 1.3961 - val_acc: 0.6441\n",
      "Epoch 4/20\n",
      "32360/32360 [==============================] - 3494s 108ms/sample - loss: 1.3428 - acc: 0.7005 - val_loss: 1.3706 - val_acc: 0.6699\n",
      "Epoch 5/20\n",
      "32360/32360 [==============================] - 3445s 106ms/sample - loss: 1.3050 - acc: 0.7384 - val_loss: 1.3562 - val_acc: 0.6817\n",
      "Epoch 6/20\n",
      "32360/32360 [==============================] - 3339s 103ms/sample - loss: 1.2715 - acc: 0.7716 - val_loss: 1.3330 - val_acc: 0.7063\n",
      "Epoch 7/20\n",
      "32360/32360 [==============================] - 3430s 106ms/sample - loss: 1.2425 - acc: 0.8010 - val_loss: 1.3279 - val_acc: 0.7125\n",
      "Epoch 8/20\n",
      " 2880/32360 [=>............................] - ETA: 48:29 - loss: 1.2241 - acc: 0.8194"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('resnet_es.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=20, validation_split = 0.25, callbacks=[earlyStopping, mcp_save])\n",
    "\n",
    "model.save('resnet_es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model and weight (only submit best model)\n",
    "best_model = model\n",
    "\n",
    "model_json = best_model.to_json()\n",
    "with open(\"resnet_fuller.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "best_model.save_weights('resnet_fuller.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 19,805,830\n",
      "Trainable params: 19,804,166\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Your model will be tested as following\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('resnet_fuller.json', 'r') as json_file:\n",
    "    json_savedModel= json_file.read()\n",
    "\n",
    "test_model = tf.keras.models.model_from_json(json_savedModel)\n",
    "test_model.summary()\n",
    "\n",
    "test_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                   optimizer='adam',\n",
    "                    metrics=['acc'])\n",
    "\n",
    "# Load weights into the new model\n",
    "test_model.load_weights('resnet_fuller.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = 'test.csv'\n",
    "image_size=(48, 48)\n",
    "\n",
    "def load_data(data_path):\n",
    "        data = pd.read_csv(data_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = data.emotion.values.reshape(-1, 1)\n",
    "        return faces, emotions\n",
    "    \n",
    "faces_test, emotions_test = load_data(data_path); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4794/4794 [==============================] - 29s 6ms/sample - loss: 2.2532 - acc: 0.8327\n",
      "Test accuracy: 0.8327075\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "test_loss, test_acc = test_model.evaluate(faces_test, emotions_test) \n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (10787, 1)\n",
      "after: (10787, 48, 48, 1)\n",
      "10787/10787 [==============================] - 64s 6ms/sample - loss: 2.9323 - acc: 0.7648\n",
      "Test accuracy: 0.7648095\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "X_test = reshape(X_test)\n",
    "test_loss, test_acc = test_model.evaluate(X_test, y_test) \n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
